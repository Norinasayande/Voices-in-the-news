{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dfbdf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting numpy>=1.17 (from datasets)\n",
      "  Using cached numpy-2.4.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-23.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (79 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Using cached multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\n",
      "  Using cached huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from datasets) (26.0)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1.0.0->datasets)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1.0.0->datasets)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting typing-extensions>=4.1.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.7.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "Using cached hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Using cached aiohttp-3.13.3-cp313-cp313-macosx_11_0_arm64.whl (490 kB)\n",
      "Using cached multidict-6.7.1-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached numpy-2.4.2-cp313-cp313-macosx_14_0_arm64.whl (5.2 MB)\n",
      "Using cached propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\n",
      "Using cached pyarrow-23.0.0-cp313-cp313-macosx_12_0_arm64.whl (34.2 MB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-macosx_10_13_universal2.whl (208 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached pandas-3.0.0-cp313-cp313-macosx_11_0_arm64.whl (9.9 MB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, urllib3, typing-extensions, tqdm, shellingham, pyyaml, pyarrow, propcache, numpy, multidict, idna, hf-xet, h11, fsspec, frozenlist, filelock, dill, click, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, typer-slim, requests, pandas, multiprocess, httpcore, anyio, aiosignal, httpx, aiohttp, huggingface-hub, datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/34\u001b[0m [datasets]/34\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 anyio-4.12.1 attrs-25.4.0 certifi-2026.1.4 charset_normalizer-3.4.4 click-8.3.1 datasets-4.5.0 dill-0.4.0 filelock-3.20.3 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.4.1 idna-3.11 multidict-6.7.1 multiprocess-0.70.18 numpy-2.4.2 pandas-3.0.0 propcache-0.4.1 pyarrow-23.0.0 pyyaml-6.0.3 requests-2.32.5 shellingham-1.5.4 tqdm-4.67.3 typer-slim-0.21.1 typing-extensions-4.15.0 urllib3-2.6.3 xxhash-3.6.0 yarl-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd214e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/GroupProjectV/Voices-in-the-news/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"1.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f261321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a small subset using streaming\n",
    "ds = load_dataset(\"abisee/cnn_dailymail\", \"1.0.0\", split=\"train[:200]\", streaming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f66743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (200, 3)\n",
      "Columns: ['article', 'highlights', 'id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
       "      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n",
       "      <td>42c027e4ff9730fbb3de84c1af0d2c506e41c3e4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Editor's note: In our Behind the Scenes series...</td>\n",
       "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
       "      <td>ee8871b15c50d0db17b0179a6d2beab35065f1e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...</td>\n",
       "      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n",
       "      <td>06352019a19ae31e527f37f7571c6dd7f0c5da37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
       "      <td>Five small polyps found during procedure; \"non...</td>\n",
       "      <td>24521a2abb2e1f5e34e6824e0f9e56904a2b0e88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN)&nbsp;&nbsp;-- The National Football League has ind...</td>\n",
       "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
       "      <td>7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  LONDON, England (Reuters) -- Harry Potter star...   \n",
       "1  Editor's note: In our Behind the Scenes series...   \n",
       "2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
       "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
       "4  (CNN)  -- The National Football League has ind...   \n",
       "\n",
       "                                          highlights  \\\n",
       "0  Harry Potter star Daniel Radcliffe gets £20M f...   \n",
       "1  Mentally ill inmates in Miami are housed on th...   \n",
       "2  NEW: \"I thought I was going to die,\" driver sa...   \n",
       "3  Five small polyps found during procedure; \"non...   \n",
       "4  NEW: NFL chief, Atlanta Falcons owner critical...   \n",
       "\n",
       "                                         id  \n",
       "0  42c027e4ff9730fbb3de84c1af0d2c506e41c3e4  \n",
       "1  ee8871b15c50d0db17b0179a6d2beab35065f1e9  \n",
       "2  06352019a19ae31e527f37f7571c6dd7f0c5da37  \n",
       "3  24521a2abb2e1f5e34e6824e0f9e56904a2b0e88  \n",
       "4  7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds.to_pandas()\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed3b1ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Downloading bertopic-0.17.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting hdbscan>=0.8.29 (from bertopic)\n",
      "  Downloading hdbscan-0.8.41-cp313-cp313-macosx_10_13_universal2.whl.metadata (15 kB)\n",
      "Collecting umap-learn>=0.5.0 (from bertopic)\n",
      "  Downloading umap_learn-0.5.11-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./.venv/lib/python3.13/site-packages (from bertopic) (2.4.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in ./.venv/lib/python3.13/site-packages (from bertopic) (3.0.0)\n",
      "Collecting plotly>=4.7.0 (from bertopic)\n",
      "  Downloading plotly-6.5.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting scikit-learn>=1.0 (from bertopic)\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
      "  Downloading sentence_transformers-5.2.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in ./.venv/lib/python3.13/site-packages (from bertopic) (4.67.3)\n",
      "Collecting llvmlite>0.36.0 (from bertopic)\n",
      "  Downloading llvmlite-0.46.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting scipy>=1.0 (from hdbscan>=0.8.29->bertopic)\n",
      "  Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.0 (from hdbscan>=0.8.29->bertopic)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
      "Collecting narwhals>=1.15.1 (from plotly>=4.7.0->bertopic)\n",
      "  Downloading narwhals-2.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from plotly>=4.7.0->bertopic) (26.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn>=1.0->bertopic)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<6.0.0,>=4.41.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers>=0.4.1->bertopic) (1.4.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading torch-2.10.0-2-cp313-none-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.15.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers<6.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading regex-2026.1.15-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<6.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<6.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (0.28.1)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (1.5.4)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (0.16.0)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading setuptools-82.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting numba>=0.51.2 (from umap-learn>=0.5.0->bertopic)\n",
      "  Downloading numba-0.63.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (2.9 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
      "  Downloading pynndescent-0.6.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting numpy>=1.20.0 (from bertopic)\n",
      "  Downloading numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (8.3.1)\n",
      "Downloading bertopic-0.17.4-py3-none-any.whl (154 kB)\n",
      "Downloading hdbscan-0.8.41-cp313-cp313-macosx_10_13_universal2.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading llvmlite-0.46.0-cp313-cp313-macosx_12_0_arm64.whl (37.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-6.5.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-2.16.0-py3-none-any.whl (443 kB)\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.2.2-py3-none-any.whl (494 kB)\n",
      "Downloading transformers-5.1.0-py3-none-any.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.2-cp39-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2026.1.15-cp313-cp313-macosx_11_0_arm64.whl (288 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading torch-2.10.0-2-cp313-none-macosx_11_0_arm64.whl (79.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading umap_learn-0.5.11-py3-none-any.whl (90 kB)\n",
      "Downloading numba-0.63.1-cp313-cp313-macosx_12_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.5-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.6.0-py3-none-any.whl (73 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading setuptools-82.0.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, threadpoolctl, sympy, setuptools, safetensors, regex, numpy, networkx, narwhals, MarkupSafe, llvmlite, joblib, scipy, plotly, numba, jinja2, torch, scikit-learn, tokenizers, pynndescent, hdbscan, umap-learn, transformers, sentence-transformers, bertopic\n",
      "\u001b[2K  Attempting uninstall: numpy0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/25\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: numpy 2.4.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/25\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling numpy-2.4.2:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/25\u001b[0m [numpy]]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.4.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/25\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [bertopic]/25\u001b[0m [sentence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 bertopic-0.17.4 hdbscan-0.8.41 jinja2-3.1.6 joblib-1.5.3 llvmlite-0.46.0 mpmath-1.3.0 narwhals-2.16.0 networkx-3.6.1 numba-0.63.1 numpy-2.3.5 plotly-6.5.2 pynndescent-0.6.0 regex-2026.1.15 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.17.0 sentence-transformers-5.2.2 setuptools-82.0.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.2 torch-2.10.0 transformers-5.1.0 umap-learn-0.5.11\n",
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.13/site-packages (5.2.2)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (5.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (2.10.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (1.8.0)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (1.17.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.67.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (82.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (8.3.1)\n",
      "Requirement already satisfied: umap-learn in ./.venv/lib/python3.13/site-packages (0.5.11)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.13/site-packages (from umap-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.3.1 in ./.venv/lib/python3.13/site-packages (from umap-learn) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in ./.venv/lib/python3.13/site-packages (from umap-learn) (1.8.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in ./.venv/lib/python3.13/site-packages (from umap-learn) (0.63.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in ./.venv/lib/python3.13/site-packages (from umap-learn) (0.6.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from umap-learn) (4.67.3)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in ./.venv/lib/python3.13/site-packages (from numba>=0.51.2->umap-learn) (0.46.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.13/site-packages (from pynndescent>=0.5->umap-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn>=1.6->umap-learn) (3.6.0)\n",
      "Requirement already satisfied: hdbscan in ./.venv/lib/python3.13/site-packages (0.8.41)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in ./.venv/lib/python3.13/site-packages (from hdbscan) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.0 in ./.venv/lib/python3.13/site-packages (from hdbscan) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in ./.venv/lib/python3.13/site-packages (from hdbscan) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.0 in ./.venv/lib/python3.13/site-packages (from hdbscan) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn>=1.6->hdbscan) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bertopic\n",
    "!pip install sentence-transformers\n",
    "!pip install umap-learn\n",
    "!pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9b48ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.13/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.13/site-packages (from nltk) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.13/site-packages (from nltk) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from nltk) (4.67.3)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nltk\n",
      "Successfully installed nltk-3.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "025257c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Now apply it\n",
    "df['clean_article'] = df['article'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6857601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on \n",
      "Cleaned: london england reuters harry potter star daniel radcliffe gains access reported million million fortune turns monday insists money wo cast spell daniel radcliffe harry potter harry potter order phoeni\n",
      "Columns: ['article', 'highlights', 'id', 'topic', 'topic_probability', 'clean_article']\n",
      "Clean article sample: london england reuters harry potter star daniel radcliffe gains access reported million million fortune turns monday insists money wo cast spell daniel radcliffe harry potter harry potter order phoeni\n"
     ]
    }
   ],
   "source": [
    "# Test on a single article first\n",
    "test_text = df['article'].iloc[0]\n",
    "print(\"Original:\", test_text[:200])\n",
    "print(\"Cleaned:\", remove_stopwords(test_text)[:200])\n",
    "\n",
    "# Check if the column was created\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"Clean article sample:\", df['clean_article'].iloc[0][:200] if 'clean_article' in df.columns else \"Column not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59110a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london england reuters harry potter star daniel radcliffe gains access reported million million fortune turns monday insists money wo cast spell daniel radcliffe harry potter harry potter order phoenix disappointment gossip columnists around world young actor says plans fritter cash away fast cars drink celebrity parties plan one people soon turn suddenly buy massive sports car collection something similar told australian interviewer earlier month think particularly extravagant things like buying things cost pounds books cds dvds radcliffe able gamble casino buy drink pub see horror film hostel part ii currently six places number one movie uk box office chart details mark landmark birthday wraps agent publicist comment plans definitely sort party said interview hopefully none reading radcliffe earnings first five potter films held trust fund able touch despite growing fame riches actor says keeping feet firmly ground people always looking say star goes rails told reporters last month try hard go way would easy latest outing boy wizard harry potter order phoenix breaking records sides atlantic reprise role last two films watch give review potter latest life beyond potter however londoner filmed tv movie called boy jack author rudyard kipling son due release later year also appear december boys australian film four boys escape orphanage earlier year made stage debut playing tortured teenager peter shaffer equus meanwhile braced even closer media scrutiny legally adult think going sort fair game told reuters friend copyright reuters rights material may published broadcast rewritten redistributed\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0, 'clean_article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97fe870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-12 12:31:46,492 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 2233.79it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Batches: 100%|██████████| 7/7 [00:01<00:00,  4.52it/s]\n",
      "2026-02-12 12:31:54,617 - BERTopic - Embedding - Completed ✓\n",
      "2026-02-12 12:31:54,618 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2026-02-12 12:31:54,645 - BERTopic - Dimensionality - Completed ✓\n",
      "2026-02-12 12:31:54,646 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2026-02-12 12:31:54,658 - BERTopic - Cluster - Completed ✓\n",
      "2026-02-12 12:31:54,671 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2026-02-12 12:31:54,749 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                      Name  \\\n",
      "0     -1     84   -1_said_cnn_fire_people   \n",
      "1      0     93     0_said_cnn_one_people   \n",
      "2      1     23  1_first_league_match_two   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [said, cnn, fire, people, one, iraq, would, pr...   \n",
      "1  [said, cnn, one, people, would, also, friend, ...   \n",
      "2  [first, league, match, two, season, win, champ...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [cnn owner north carolina beach house seven co...  \n",
      "1  [cnn hands feet shackled face obscured long ha...  \n",
      "2  [paris france world number three novak djokovi...  \n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize BERTopic\n",
    "topic_model = BERTopic(verbose=True, embedding_model=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Fit on the article text\n",
    "topics, probs = topic_model.fit_transform(df['clean_article'])\n",
    "\n",
    "# Add topics to your DataFrame\n",
    "df['topic'] = topics\n",
    "df['topic_probability'] = probs\n",
    "\n",
    "# Get topic info\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "335249e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: [('said', np.float64(0.0654790754896595)), ('cnn', np.float64(0.024970182912239895)), ('one', np.float64(0.01754709862002885)), ('people', np.float64(0.017465874703789734)), ('would', np.float64(0.016863380684911066)), ('also', np.float64(0.015383178215519227)), ('friend', np.float64(0.015266798647712746)), ('told', np.float64(0.0143875048387377)), ('years', np.float64(0.013403281147506415)), ('year', np.float64(0.01288936163585053))]\n",
      "Topic 1: [('first', np.float64(0.03918853637534424)), ('league', np.float64(0.0381746221870882)), ('match', np.float64(0.03785307450756452)), ('two', np.float64(0.03685074181730009)), ('season', np.float64(0.03611152651795604)), ('win', np.float64(0.032118914568971715)), ('champions', np.float64(0.03181179479466597)), ('club', np.float64(0.03129650649680841)), ('italy', np.float64(0.030686881026162845)), ('milan', np.float64(0.030605716825643777))]\n",
      "Topic 2: False\n"
     ]
    }
   ],
   "source": [
    "# Print top topics\n",
    "for topic_num in range(min(10, len(topic_info))):\n",
    "    if topic_num != -1:  # -1 is outlier topic\n",
    "        print(f\"Topic {topic_num}: {topic_model.get_topic(topic_num)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "071e694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                      Name  \\\n",
      "0     -1     84   -1_said_cnn_fire_people   \n",
      "1      0     93     0_said_cnn_one_people   \n",
      "2      1     23  1_first_league_match_two   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [said, cnn, fire, people, one, iraq, would, pr...   \n",
      "1  [said, cnn, one, people, would, also, friend, ...   \n",
      "2  [first, league, match, two, season, win, champ...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [cnn owner north carolina beach house seven co...  \n",
      "1  [cnn hands feet shackled face obscured long ha...  \n",
      "2  [paris france world number three novak djokovi...  \n"
     ]
    }
   ],
   "source": [
    "# Get detailed topic information\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head(15))  # Show top 15 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5efda82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: ['said', 'cnn', 'one', 'people', 'would', 'also', 'friend', 'told', 'years', 'year']\n",
      "\n",
      "Topic 1: ['first', 'league', 'match', 'two', 'season', 'win', 'champions', 'club', 'italy', 'milan']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print each topic with its top words\n",
    "for topic_num in topic_info['Topic']:\n",
    "    if topic_num != -1:  # Skip outlier topic\n",
    "        words = topic_model.get_topic(topic_num)\n",
    "        print(f\"Topic {topic_num}: {[word for word, score in words[:10]]}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
